{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7_8vNAESkpk"
   },
   "source": [
    "# RNN model Stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6M2TZQJNSkpm"
   },
   "source": [
    "## 1. import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FbTINRKNSkpp",
    "outputId": "439f8d2c-ed21-40ca-d69c-d534e69d1c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88z3ykY8Skp3"
   },
   "source": [
    "## 2. Set hyperparameters\n",
    "\n",
    "- 1. learning rate　: lr = 0.001\n",
    "- 2. Parameter :　batch_size = 128\n",
    "- 3. epoch : epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDFrHu9gSkp4"
   },
   "outputs": [],
   "source": [
    "lr =  0.0001\n",
    "batch_size = 22\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JwvURyIcSkp9"
   },
   "source": [
    "## 3. Load data and preprocess\n",
    "- 導入 28*28 mnist pixel的數字辨識圖  : tf.keras.datasets.mnist.load_data()\n",
    "- 28*28 : 28個time_step每個time_step有28個維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD-C3</th>\n",
       "      <th>MA5</th>\n",
       "      <th>TS-9</th>\n",
       "      <th>TS-6</th>\n",
       "      <th>Corp 3</th>\n",
       "      <th>Corp2</th>\n",
       "      <th>MA10</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.11</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MACD   MACD-C3  MA5   TS-9   TS-6  Corp 3  Corp2  MA10  Target\n",
       "299   0.11     -0.89  0.1      0      0       1      0 -0.25       0\n",
       "298   0.21     -0.79  1.1      0      0       1      0 -0.10       0\n",
       "297   0.11      1.11  1.8      0      0      -1      0  0.35       0\n",
       "296   0.16     -0.84  1.4     -1      0       1      1  0.45       0\n",
       "295  -0.04      0.96  0.5      0      0      -1      0  0.75      -1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pima = pd.read_csv(\"./abcW_2.csv\")\n",
    "reverse_stockseq = pima.iloc[::-1]\n",
    "reverse_stockseq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將 Target -1 -> 2\n",
    "reverse_stockseq.iloc[0:299, 8][reverse_stockseq.iloc[0:299, 8]==-1]=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD-C3</th>\n",
       "      <th>MA5</th>\n",
       "      <th>TS-9</th>\n",
       "      <th>TS-6</th>\n",
       "      <th>Corp 3</th>\n",
       "      <th>Corp2</th>\n",
       "      <th>MA10</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.11</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MACD   MACD-C3  MA5   TS-9   TS-6  Corp 3  Corp2  MA10  Target\n",
       "299   0.11     -0.89  0.1      0      0       1      0 -0.25       0\n",
       "298   0.21     -0.79  1.1      0      0       1      0 -0.10       0\n",
       "297   0.11      1.11  1.8      0      0      -1      0  0.35       0\n",
       "296   0.16     -0.84  1.4     -1      0       1      1  0.45       0\n",
       "295  -0.04      0.96  0.5      0      0      -1      0  0.75       2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_stockseq.head()\n",
    "#reverse_stockseq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#統計 -1(2)總數 : \n",
    "#np.sum(reverse_stockseq.iloc[0:299, 8]==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas -> numpy \n",
    "data = np.array(reverse_stockseq.iloc[0:300])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(data, window_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    i = 0\n",
    "    while (i + window_size) <= len(data):\n",
    "        X.append(data[i:i+window_size,:8]) # 前n筆資料訓練\n",
    "        y.append(data[i+window_size-1,8])   # 最後一筆預測\n",
    "        \n",
    "        i += 1\n",
    "    assert len(X) ==  len(y)  #做完所有資料return\n",
    "    return np.array(X), np.int32(y)\n",
    "\n",
    "window_size = 10\n",
    "X, y = window_data(data, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse_stockseq.iloc[0:299, 8]\n",
    "#X = reverse_stockseq.iloc[0:299, 0:8].values # Features\n",
    "#y = reverse_stockseq.iloc[0:299, 8:9].values  # Target variable\n",
    "#y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before_X= (291, 10, 8)\n",
      "before_y= (291,)\n",
      "(291, 80)\n",
      "(291, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"before_X=\",X.shape)\n",
    "print(\"before_y=\",y.shape)\n",
    "X = X.reshape([291, -1])\n",
    "y = y.reshape([291, -1])\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = reverse_stockseq.iloc[0:299, 0:8].values # Features\n",
    "# y = reverse_stockseq.iloc[0:299, 8:9].values  # Target variable\n",
    "\n",
    "X_train1=X\n",
    "y_train1=y \n",
    "\n",
    "X_test1 = X\n",
    "y_test1 = y\n",
    "\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train1 = sc.fit_transform(X_train1)\n",
    "X_test1 =  sc.fit_transform(X_test1)\n",
    "\n",
    "X_train = X_train1[0:250].reshape([-1, 10, 8])\n",
    "y_train = y_train1[0:250]\n",
    "\n",
    "X_test = X_test1[250:].reshape([-1, 10, 8])\n",
    "y_test = y_test1[250:]\n",
    "\n",
    "\n",
    "#X_train1.shape\n",
    "#y_train\n",
    "#X_test\n",
    "#y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 10, 8)\n",
      "(250, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 確認匯入進來的圖片 size 與 Appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Data Shape', X_train[9].shape)  # 印出圖片shape \n",
    "# print('Label: ', y_train[0])\n",
    "\n",
    "#plt.figure(figsize = (5,5)) #圖片size\n",
    "#plt.imshow(x_train[1], cmap = 'gray') #try : cmap = binary :黑白灰階 \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Data Preprocess \n",
    "\n",
    "- (Normalization / One-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "#X_train = X_train / 255.\n",
    "#X_test = X_test / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding : -> [1,0,0] , [0,1,0] , [0,0,1]\n",
    "\n",
    "y_train = np.eye(3)[np.int32(y_train[:])].reshape([-1,3])\n",
    "y_test = np.eye(3)[np.int32(y_test[:])].reshape([-1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 定義Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0PHNnOMMSkqF"
   },
   "outputs": [],
   "source": [
    "def batch_gen(X, y, batch_size):\n",
    "    X, y = shuffle(X, y)\n",
    "    batch_index = 0\n",
    "    \n",
    "    while batch_index < len(X):\n",
    "        batch_X = X[batch_index : batch_index+batch_size]\n",
    "        batch_y = y[batch_index : batch_index+batch_size]\n",
    "        batch_index += batch_size\n",
    "        yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XbnKyllZSkqI"
   },
   "source": [
    "## 4. Build the graph (定義RNN Model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1.選擇 RNNcell , Ex : 這邊用BasicRNNCell , 此外還有許多其他的種類 例如 : RCN GRU...等<br>\n",
    "\n",
    "- 2.使用dynamic_rnn 操作RNN網絡架構細節. 只需將這幾項輸入 \"BasicRNN_cell, inputs, initial_state \" ,即可運算<BR>\n",
    "    \n",
    "- 3.hidden layer(initial_state 如何設?) <br>\n",
    "    兩種做法:<br>\n",
    "    方法一 : initial_ state 跟output結果是一樣長的 : \n",
    "        a.設Batch_size : tf.shape(0), \n",
    "        b.output維度: 設定輸出維度 : (num_units=units) unit 可用其他維度替換 <br>\n",
    "        c.init_state = tf.zeros([tf.shape(inputs)[0], units])<br>\n",
    "        \n",
    "    方法二 : 使用zero_state叫出batchsize : (tf.shape(inputs)[0])\n",
    "input(Xt) , initial_state(ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r1g79mkSkqJ"
   },
   "outputs": [],
   "source": [
    "def RNN_layer(inputs, units):\n",
    "    \n",
    "    BasicRNN_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=units)\n",
    "    \n",
    "    init_state = tf.zeros([tf.shape(inputs)[0], units])\n",
    "    init_state = BasicRNN_cell.zero_state(tf.shape(inputs)[0], dtype=tf.float32) # shape = (batch, units)\n",
    "    \n",
    "    outputs, states = tf.nn.dynamic_rnn(BasicRNN_cell, inputs, initial_state=init_state)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立RNN MODEL : \n",
    " - 1. 建立placeholder<BR>\n",
    "\n",
    " - 2. 轉換成output有32維 :\n",
    "    with tf.variable_scope(\"RNN_layer\"): <br>\n",
    "    outputs = RNN_layer(input_data, 32)<br>\n",
    "    \n",
    " - 3. 只需要取最後一個Time_step 座位最後輸出 :　RNN_last_outputs = outputs[:,-1,:]\n",
    " \n",
    " \n",
    " - 4. Evaluate : loss/ optimizer/ accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zks8EhaKSkqL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-d07cb42c40f3>:3: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-13-d07cb42c40f3>:8: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-14-d77129835423>:12: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_data = tf.placeholder(dtype=tf.float32, shape=[None, 10, 8], name='input_data')\n",
    "    y_label = tf.placeholder(dtype=tf.float32, shape=[None, 3], name='label')\n",
    "\n",
    "with tf.variable_scope(\"RNN_layer\"):\n",
    "    outputs = RNN_layer(input_data, 56)\n",
    "\n",
    "with tf.variable_scope(\"output_layer\"):\n",
    "    RNN_last_outputs = outputs[:,-1,:]  # outputs shape = (batch, timestep, feature)\n",
    "    prediction = tf.layers.dense(inputs=RNN_last_outputs, units=3)\n",
    "\n",
    "\n",
    "# Evaluate  \n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y_label))\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check一下Output :   shape=(?, 28, 32)  \n",
    "  - ? : batch_size,<br>\n",
    "  - 時間序: t = 28 <br>\n",
    "  - 我們要轉換成的維度: 32<br>\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qdiHQwiSSkqO",
    "outputId": "2f9e2042-1058-47b0-e600-2c2b1a53bcee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'RNN_layer/rnn/transpose_1:0' shape=(?, 8, 32) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們只取最後一個時間點 : RNN_last_outputs\n",
    "    \n",
    "   - shape=(?, 32)\n",
    "   - 時間序28只取最後1個timing\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDsBFqFtSkqQ",
    "outputId": "dd0a1763-2564-499a-f854-194a7990724d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'output_layer/strided_slice:0' shape=(?, 32) dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_last_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看創建的變數 : \n",
    "\n",
    "  - 只看前面四筆!\n",
    "  - shape : (Input維度 28維 + 轉換維度 32維 , 轉換32維) (M+N, M), shape=(60, 32)\n",
    "  - dense(weight : 32接到10)\n",
    "  - bias = 10個"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7eB_jOw3SkqT",
    "outputId": "6daf6d85-627a-4318-90cb-17f8aab3bf0d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'RNN_layer/rnn/basic_rnn_cell/kernel:0' shape=(33, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'RNN_layer/rnn/basic_rnn_cell/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel:0' shape=(32, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias:0' shape=(3,) dtype=float32_ref>,\n",
       " <tf.Variable 'optimizer/beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'optimizer/beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'RNN_layer/rnn/basic_rnn_cell/kernel/Adam:0' shape=(33, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'RNN_layer/rnn/basic_rnn_cell/kernel/Adam_1:0' shape=(33, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'RNN_layer/rnn/basic_rnn_cell/bias/Adam:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'RNN_layer/rnn/basic_rnn_cell/bias/Adam_1:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel/Adam:0' shape=(32, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/kernel/Adam_1:0' shape=(32, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias/Adam:0' shape=(3,) dtype=float32_ref>,\n",
       " <tf.Variable 'output_layer/dense/bias/Adam_1:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =  0.0001\n",
    "batch_size = 20\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## 建立MODEL更迅速的方式: tf.keras !!\n",
    "    \n",
    "    \n",
    "    1.一樣先建立placeholder\n",
    "    2.叫出keras.SimpleRNN(設定維度)(設定Input資料)\n",
    "      !!! 在這邊 rnn_out的意思及表示最後時間序輸出 RNN_last_outputs  \n",
    "    3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "398XqnyRSkqV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-15-d5d0f1fbf38e>:13: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "# with tf.keras\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_data = tf.placeholder(dtype=tf.float32, shape=[None, 10, 8], name='input_data')\n",
    "    y_label = tf.placeholder(dtype=tf.float32, shape=[None, 3], name='label')\n",
    "\n",
    "with tf.variable_scope(\"RNN_layer\"):\n",
    "    rnn_out = tf.keras.layers.SimpleRNN(units=32)(input_data)\n",
    "\n",
    "with tf.variable_scope(\"output_layer\"):\n",
    "    prediction = tf.layers.dense(inputs=rnn_out, units=3)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y_label))\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nx-ejy-ESkqY"
   },
   "source": [
    "## 5. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "712veiFdSkqY"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0S21HnJjSkqa",
    "outputId": "cda6f414-3e45-481d-adf2-37742781ddf0"
   },
   "outputs": [],
   "source": [
    "for epoch_index in range(epochs):\n",
    "    loss_ls, acc_ls = [], []\n",
    "    get_batch = batch_gen(X_train, y_train, batch_size)\n",
    "    \n",
    "    for batch_X, batch_y in get_batch:\n",
    "        _,  batch_acc, batch_loss = sess.run([opt, accuracy, loss], feed_dict={input_data: batch_X, y_label:batch_y})\n",
    "        loss_ls.append(batch_loss)\n",
    "        acc_ls.append(batch_acc)\n",
    "\n",
    " #   print(\"Epoch \", epoch_index)\n",
    "  #  print(\"Accuracy \", np.mean(acc_ls), \"     Loss \", np.mean(loss_ls))\n",
    "   # print(\"__________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rt4d3VKhSkqc",
    "outputId": "c42b25aa-0336-4cfd-d946-f036a93779d6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6097561\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", sess.run(accuracy, feed_dict={input_data: X_test, y_label: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 10, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qnA2CmiSkqg"
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_0ZWlL13Skql"
   },
   "source": [
    "## Practice 1\n",
    "- ### 1. 把RNN cell換成LSTM觀察Accuracy是否會上升? (hint: tf.nn.rnn_cell.BasicLSTMCell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# X_train1=X\n",
    "# y_train1=y \n",
    "\n",
    "# X_test1 = X\n",
    "# y_test1 = y\n",
    "\n",
    "\n",
    "\n",
    "# # Feature Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train1 = sc.fit_transform(X_train1)\n",
    "\n",
    "\n",
    "\n",
    "# X_train = X_train1[0:250].reshape([-1, 7, 8])\n",
    "# y_train = y_train1[0:250]\n",
    "\n",
    "# X_test = X_test1[250:].reshape([-1, 7, 8])\n",
    "# y_test = y_test1[250:]\n",
    "\n",
    "# y_train = np.eye(3)[np.int32(y_train[:])].reshape([-1,3])\n",
    "# y_test = np.eye(3)[np.int32(y_test[:])].reshape([-1,3])\n",
    "\n",
    "\n",
    "# def batch_gen(X, y, batch_size):\n",
    "#     X, y = shuffle(X, y)\n",
    "#     batch_index = 0\n",
    "    \n",
    "#     while batch_index < len(X):\n",
    "#         batch_X = X[batch_index : batch_index+batch_size]\n",
    "#         batch_y = y[batch_index : batch_index+batch_size]\n",
    "#         batch_index += batch_size\n",
    "#         yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_layer(inputs, units):\n",
    "    \n",
    "    BasicRNN_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=units)\n",
    "    \n",
    "    init_state = tf.zeros([tf.shape(inputs)[0], units])\n",
    "    init_state = BasicLSTM_cell.zero_state(tf.shape(inputs)[0], dtype=tf.float32) # shape = (batch, units)\n",
    "    \n",
    "    outputs, states = tf.nn.dynamic_rnn(BasicLSTMCell, inputs, initial_state=init_state)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_data = tf.placeholder(dtype=tf.float32, shape=[None, 10, 8], name='input_data')\n",
    "    y_label = tf.placeholder(dtype=tf.float32, shape=[None, 3], name='label')\n",
    "\n",
    "with tf.variable_scope(\"LSTM_layer\"):\n",
    "    rnn_out = tf.keras.layers.LSTM(units=56)(input_data)\n",
    "\n",
    "with tf.variable_scope(\"output_layer\"):\n",
    "    prediction = tf.layers.dense(inputs=rnn_out, units=3)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y_label))\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_index in range(epochs):\n",
    "    loss_ls, acc_ls = [], []\n",
    "    get_batch = batch_gen(X_train, y_train, batch_size)\n",
    "    \n",
    "    for batch_X, batch_y in get_batch:\n",
    "        _,  batch_acc, batch_loss = sess.run([opt, accuracy, loss], feed_dict={input_data: batch_X, y_label:batch_y})\n",
    "        loss_ls.append(batch_loss)\n",
    "        acc_ls.append(batch_acc)\n",
    "\n",
    "  #  print(\"Epoch \", epoch_index)\n",
    "  #  print(\"Accuracy \", np.mean(acc_ls), \"     Loss \", np.mean(loss_ls))\n",
    "  #  print(\"__________________\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6097561\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", sess.run(accuracy, feed_dict={input_data: X_test, y_label: y_test}))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 2. 把RNN cell換成GRU觀察Accuracy是否會上升? (hint: tf.nn.rnn_cell.GRUCell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =  0.0001\n",
    "batch_size = 20\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_data = tf.placeholder(dtype=tf.float32, shape=[None, 10, 8], name='input_data')\n",
    "    y_label = tf.placeholder(dtype=tf.float32, shape=[None, 3], name='label')\n",
    "\n",
    "with tf.variable_scope(\"GRU_layer\"):\n",
    "    rnn_out = tf.keras.layers.GRU(units=55)(input_data)\n",
    "\n",
    "with tf.variable_scope(\"output_layer\"):\n",
    "    prediction = tf.layers.dense(inputs=rnn_out, units=3)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y_label))\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_index in range(epochs):\n",
    "    loss_ls, acc_ls = [], []\n",
    "    get_batch = batch_gen(X_train, y_train, batch_size)\n",
    "    \n",
    "    for batch_X, batch_y in get_batch:\n",
    "        _,  batch_acc, batch_loss = sess.run([opt, accuracy, loss], feed_dict={input_data: batch_X, y_label:batch_y})\n",
    "        loss_ls.append(batch_loss)\n",
    "        acc_ls.append(batch_acc)\n",
    "\n",
    "#    print(\"Epoch \", epoch_index)\n",
    "#    print(\"Accuracy \", np.mean(acc_ls), \"     Loss \", np.mean(loss_ls))\n",
    "#    print(\"__________________\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6097561\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", sess.run(accuracy, feed_dict={input_data: X_test, y_label: y_test}))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g63G7kdZSkql"
   },
   "source": [
    "## Practice 2\n",
    "把手寫數字兩張平行輸入到model預測，輸入資料變成time_step = 28, input_data_dimension = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1V0l69HsSkqm",
    "outputId": "44810993-0fcb-4e6d-9701-ad49969c7574"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show training data\n",
    "plt.figure(figsize=(20,10))\n",
    "img1 = x_train[0]\n",
    "img2 = x_train[1]\n",
    "img = np.concatenate((img1,img2),axis=1)  \n",
    "plt.imshow(img, cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train / 255.\n",
    "# x_test = x_test / 255.\n",
    "\n",
    "# #one-hot encoding\n",
    "# y_train = np.eye(10)[y_train[:]]\n",
    "# y_test = np.eye(10)[y_test[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gen(X, y, batch_size):\n",
    "    X, y = shuffle(X, y)\n",
    "    batch_index = 0\n",
    "    \n",
    "    while batch_index < len(X):\n",
    "        batch_X = X[batch_index : batch_index+batch_size]\n",
    "        batch_y = y[batch_index : batch_index+batch_size]\n",
    "        batch_index += batch_size\n",
    "        yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3new\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-7-79a71c3ce064>:11: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3new\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_data = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='input_data')\n",
    "    y_label = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='label')\n",
    "\n",
    "with tf.variable_scope(\"RNN_layer\"):\n",
    "    rnn_out = tf.keras.layers.SimpleRNN(units=56)(input_data)\n",
    "\n",
    "with tf.variable_scope(\"output_layer\"):\n",
    "    prediction = tf.layers.dense(inputs=rnn_out, units=10)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y_label))\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Accuracy  0.7566576      Loss  0.7860067\n",
      "__________________\n",
      "Epoch  1\n",
      "Accuracy  0.89718264      Loss  0.3600037\n",
      "__________________\n",
      "Epoch  2\n",
      "Accuracy  0.91836023      Loss  0.28714517\n",
      "__________________\n",
      "Epoch  3\n",
      "Accuracy  0.9303982      Loss  0.24651988\n",
      "__________________\n",
      "Epoch  4\n",
      "Accuracy  0.93665045      Loss  0.22317748\n",
      "__________________\n",
      "Epoch  5\n",
      "Accuracy  0.9409093      Loss  0.20675164\n",
      "__________________\n",
      "Epoch  6\n",
      "Accuracy  0.94696164      Loss  0.18967788\n",
      "__________________\n",
      "Epoch  7\n",
      "Accuracy  0.94796664      Loss  0.18363197\n",
      "__________________\n",
      "Epoch  8\n",
      "Accuracy  0.95192564      Loss  0.16930941\n",
      "__________________\n",
      "Epoch  9\n",
      "Accuracy  0.9552128      Loss  0.16080622\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "for epoch_index in range(epochs):\n",
    "    loss_ls, acc_ls = [], []\n",
    "    get_batch = batch_gen(x_train, y_train, batch_size)\n",
    "    \n",
    "    for batch_X, batch_y in get_batch:\n",
    "        _,  batch_acc, batch_loss = sess.run([opt, accuracy, loss], feed_dict={input_data: batch_X, y_label:batch_y})\n",
    "        loss_ls.append(batch_loss)\n",
    "        acc_ls.append(batch_acc)\n",
    "\n",
    "    print(\"Epoch \", epoch_index)\n",
    "    print(\"Accuracy \", np.mean(acc_ls), \"     Loss \", np.mean(loss_ls))\n",
    "    print(\"__________________\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_data = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='input_data')\n",
    "    y_label = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='label')\n",
    "\n",
    "with tf.variable_scope(\"LSTM_layer\"):\n",
    "    rnn_out = tf.keras.layers.LSTM(units=56)(input_data)\n",
    "\n",
    "with tf.variable_scope(\"output_layer\"):\n",
    "    prediction = tf.layers.dense(inputs=rnn_out, units=10)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y_label))\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Accuracy  0.7791789      Loss  0.69145596\n",
      "__________________\n",
      "Epoch  1\n",
      "Accuracy  0.9390547      Loss  0.20668374\n",
      "__________________\n",
      "Epoch  2\n",
      "Accuracy  0.95751154      Loss  0.14267193\n",
      "__________________\n",
      "Epoch  3\n",
      "Accuracy  0.9657849      Loss  0.11333728\n",
      "__________________\n",
      "Epoch  4\n",
      "Accuracy  0.97146523      Loss  0.09473352\n",
      "__________________\n",
      "Epoch  5\n",
      "Accuracy  0.97435254      Loss  0.08407584\n",
      "__________________\n",
      "Epoch  6\n",
      "Accuracy  0.9786947      Loss  0.0709015\n",
      "__________________\n",
      "Epoch  7\n",
      "Accuracy  0.98030496      Loss  0.06577982\n",
      "__________________\n",
      "Epoch  8\n",
      "Accuracy  0.982526      Loss  0.057980765\n",
      "__________________\n",
      "Epoch  9\n",
      "Accuracy  0.9842084      Loss  0.053839434\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "for epoch_index in range(epochs):\n",
    "    loss_ls, acc_ls = [], []\n",
    "    get_batch = batch_gen(x_train, y_train, batch_size)\n",
    "    \n",
    "    for batch_X, batch_y in get_batch:\n",
    "        _,  batch_acc, batch_loss = sess.run([opt, accuracy, loss], feed_dict={input_data: batch_X, y_label:batch_y})\n",
    "        loss_ls.append(batch_loss)\n",
    "        acc_ls.append(batch_acc)\n",
    "\n",
    "    print(\"Epoch \", epoch_index)\n",
    "    print(\"Accuracy \", np.mean(acc_ls), \"     Loss \", np.mean(loss_ls))\n",
    "    print(\"__________________\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.981\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", sess.run(accuracy, feed_dict={input_data: x_test, y_label: y_test}))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_data = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='input_data')\n",
    "    y_label = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='label')\n",
    "\n",
    "with tf.variable_scope(\"GRU_layer\"):\n",
    "    rnn_out = tf.keras.layers.GRU(units=56)(input_data)\n",
    "\n",
    "with tf.variable_scope(\"output_layer\"):\n",
    "    prediction = tf.layers.dense(inputs=rnn_out, units=10)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y_label))\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Accuracy  0.68169194      Loss  0.92351145\n",
      "__________________\n",
      "Epoch  1\n",
      "Accuracy  0.91298527      Loss  0.2972057\n",
      "__________________\n",
      "Epoch  2\n",
      "Accuracy  0.94554573      Loss  0.18404277\n",
      "__________________\n",
      "Epoch  3\n",
      "Accuracy  0.9600602      Loss  0.1334661\n",
      "__________________\n",
      "Epoch  4\n",
      "Accuracy  0.9679504      Loss  0.1085466\n",
      "__________________\n",
      "Epoch  5\n",
      "Accuracy  0.97233695      Loss  0.092760995\n",
      "__________________\n",
      "Epoch  6\n",
      "Accuracy  0.9755797      Loss  0.08218741\n",
      "__________________\n",
      "Epoch  7\n",
      "Accuracy  0.9778563      Loss  0.073058106\n",
      "__________________\n",
      "Epoch  8\n",
      "Accuracy  0.9806548      Loss  0.06482837\n",
      "__________________\n",
      "Epoch  9\n",
      "Accuracy  0.9817486      Loss  0.06075497\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch_index in range(epochs):\n",
    "    loss_ls, acc_ls = [], []\n",
    "    get_batch = batch_gen(x_train, y_train, batch_size)\n",
    "    \n",
    "    for batch_X, batch_y in get_batch:\n",
    "        _,  batch_acc, batch_loss = sess.run([opt, accuracy, loss], feed_dict={input_data: batch_X, y_label:batch_y})\n",
    "        loss_ls.append(batch_loss)\n",
    "        acc_ls.append(batch_acc)\n",
    "\n",
    "    print(\"Epoch \", epoch_index)\n",
    "    print(\"Accuracy \", np.mean(acc_ls), \"     Loss \", np.mean(loss_ls))\n",
    "    print(\"__________________\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9777\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", sess.run(accuracy, feed_dict={input_data: x_test, y_label: y_test}))        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_data = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='input_data')\n",
    "    y_label = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='label')\n",
    "\n",
    "with tf.variable_scope(\"RNN_layer\"):\n",
    "    rnn_out = tf.keras.layers.SimpleRNN(units=100)(input_data)\n",
    "\n",
    "with tf.variable_scope(\"output_layer\"):\n",
    "    prediction = tf.layers.dense(inputs=rnn_out, units=10)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y_label))\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Accuracy  0.843489      Loss  0.51268744\n",
      "__________________\n",
      "Epoch  1\n",
      "Accuracy  0.9321695      Loss  0.2313214\n",
      "__________________\n",
      "Epoch  2\n",
      "Accuracy  0.9474669      Loss  0.18275169\n",
      "__________________\n",
      "Epoch  3\n",
      "Accuracy  0.9550961      Loss  0.15722844\n",
      "__________________\n",
      "Epoch  4\n",
      "Accuracy  0.9580446      Loss  0.1451658\n",
      "__________________\n",
      "Epoch  5\n",
      "Accuracy  0.96495205      Loss  0.12429775\n",
      "__________________\n",
      "Epoch  6\n",
      "Accuracy  0.9658627      Loss  0.12052713\n",
      "__________________\n",
      "Epoch  7\n",
      "Accuracy  0.96726745      Loss  0.11331634\n",
      "__________________\n",
      "Epoch  8\n",
      "Accuracy  0.9699327      Loss  0.10467012\n",
      "__________________\n",
      "Epoch  9\n",
      "Accuracy  0.9711599      Loss  0.09927214\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch_index in range(epochs):\n",
    "    loss_ls, acc_ls = [], []\n",
    "    get_batch = batch_gen(x_train, y_train, batch_size)\n",
    "    \n",
    "    for batch_X, batch_y in get_batch:\n",
    "        _,  batch_acc, batch_loss = sess.run([opt, accuracy, loss], feed_dict={input_data: batch_X, y_label:batch_y})\n",
    "        loss_ls.append(batch_loss)\n",
    "        acc_ls.append(batch_acc)\n",
    "\n",
    "    print(\"Epoch \", epoch_index)\n",
    "    print(\"Accuracy \", np.mean(acc_ls), \"     Loss \", np.mean(loss_ls))\n",
    "    print(\"__________________\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy:\", sess.run(accuracy, feed_dict={input_data: x_test, y_label: y_test}))        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_data = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='input_data')\n",
    "    y_label = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='label')\n",
    "\n",
    "with tf.variable_scope(\"LSTM_layer\"):\n",
    "    rnn_out = tf.keras.layers.LSTM(units=100)(input_data)\n",
    "\n",
    "with tf.variable_scope(\"output_layer\"):\n",
    "    prediction = tf.layers.dense(inputs=rnn_out, units=10)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y_label))\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Accuracy  0.8184913      Loss  0.5676457\n",
      "__________________\n",
      "Epoch  1\n",
      "Accuracy  0.95134264      Loss  0.16121063\n",
      "__________________\n",
      "Epoch  2\n",
      "Accuracy  0.9682114      Loss  0.109148845\n",
      "__________________\n",
      "Epoch  3\n",
      "Accuracy  0.9746802      Loss  0.08413724\n",
      "__________________\n",
      "Epoch  4\n",
      "Accuracy  0.9786114      Loss  0.071018115\n",
      "__________________\n",
      "Epoch  5\n",
      "Accuracy  0.98203176      Loss  0.058878724\n",
      "__________________\n",
      "Epoch  6\n",
      "Accuracy  0.98427504      Loss  0.05076241\n",
      "__________________\n",
      "Epoch  7\n",
      "Accuracy  0.985591      Loss  0.045725904\n",
      "__________________\n",
      "Epoch  8\n",
      "Accuracy  0.98704576      Loss  0.041170955\n",
      "__________________\n",
      "Epoch  9\n",
      "Accuracy  0.9888337      Loss  0.035214934\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "for epoch_index in range(epochs):\n",
    "    loss_ls, acc_ls = [], []\n",
    "    get_batch = batch_gen(x_train, y_train, batch_size)\n",
    "    \n",
    "    for batch_X, batch_y in get_batch:\n",
    "        _,  batch_acc, batch_loss = sess.run([opt, accuracy, loss], feed_dict={input_data: batch_X, y_label:batch_y})\n",
    "        loss_ls.append(batch_loss)\n",
    "        acc_ls.append(batch_acc)\n",
    "\n",
    "    print(\"Epoch \", epoch_index)\n",
    "    print(\"Accuracy \", np.mean(acc_ls), \"     Loss \", np.mean(loss_ls))\n",
    "    print(\"__________________\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.983\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", sess.run(accuracy, feed_dict={input_data: x_test, y_label: y_test}))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    input_data = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='input_data')\n",
    "    y_label = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='label')\n",
    "\n",
    "with tf.variable_scope(\"GRU_layer\"):\n",
    "    rnn_out = tf.keras.layers.GRU(units=100)(input_data)\n",
    "\n",
    "with tf.variable_scope(\"output_layer\"):\n",
    "    prediction = tf.layers.dense(inputs=rnn_out, units=10)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y_label))\n",
    "\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))    \n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Accuracy  0.77233255      Loss  0.67397505\n",
      "__________________\n",
      "Epoch  1\n",
      "Accuracy  0.94938815      Loss  0.1720536\n",
      "__________________\n",
      "Epoch  2\n",
      "Accuracy  0.9659848      Loss  0.11458288\n",
      "__________________\n",
      "Epoch  3\n",
      "Accuracy  0.9736141      Loss  0.08664762\n",
      "__________________\n",
      "Epoch  4\n",
      "Accuracy  0.9784615      Loss  0.07254567\n",
      "__________________\n",
      "Epoch  5\n",
      "Accuracy  0.9815265      Loss  0.059818693\n",
      "__________________\n",
      "Epoch  6\n",
      "Accuracy  0.9841529      Loss  0.051573038\n",
      "__________________\n",
      "Epoch  7\n",
      "Accuracy  0.98600745      Loss  0.045067307\n",
      "__________________\n",
      "Epoch  8\n",
      "Accuracy  0.9875122      Loss  0.04120541\n",
      "__________________\n",
      "Epoch  9\n",
      "Accuracy  0.988495      Loss  0.035802316\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch_index in range(epochs):\n",
    "    loss_ls, acc_ls = [], []\n",
    "    get_batch = batch_gen(x_train, y_train, batch_size)\n",
    "    \n",
    "    for batch_X, batch_y in get_batch:\n",
    "        _,  batch_acc, batch_loss = sess.run([opt, accuracy, loss], feed_dict={input_data: batch_X, y_label:batch_y})\n",
    "        loss_ls.append(batch_loss)\n",
    "        acc_ls.append(batch_acc)\n",
    "\n",
    "    print(\"Epoch \", epoch_index)\n",
    "    print(\"Accuracy \", np.mean(acc_ls), \"     Loss \", np.mean(loss_ls))\n",
    "    print(\"__________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", sess.run(accuracy, feed_dict={input_data: x_test, y_label: y_test}))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "01_MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
